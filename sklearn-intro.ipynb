{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries\n",
    "\n",
    "Note the difference between `import` and `from` x `import` y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(boston['DESCR'][292:1225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=506, minmax=(5.0, 50.0), mean=22.532806324110677, variance=84.586723594098558, skewness=1.104810822864635, kurtosis=1.4686287722747462)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "y = boston['target']\n",
    "\n",
    "stats.describe(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMSaCWOgbY0wEsdA3xpgI8v8Bie9ZAA1RqE8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2356afeb358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.distplot(y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "          boston['data']\n",
    "        , boston['target']\n",
    "        , test_size=0.33\n",
    "        , random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression example\n",
    "\n",
    "ESTIMATOR.fit(predictors, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "linear_regression = lm.LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model R_Square on the holdout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72585158182300469"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get coefficients of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.12806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.0378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.05861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>3.24007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-16.22227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.89352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.01279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.42327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.23451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.92995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.01192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.54849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature Coefficient\n",
       "0      CRIM    -0.12806\n",
       "1        ZN      0.0378\n",
       "2     INDUS     0.05861\n",
       "3      CHAS     3.24007\n",
       "4       NOX   -16.22227\n",
       "5        RM     3.89352\n",
       "6       AGE    -0.01279\n",
       "7       DIS    -1.42327\n",
       "8       RAD     0.23451\n",
       "9       TAX     -0.0082\n",
       "10  PTRATIO    -0.92995\n",
       "11        B     0.01192\n",
       "12    LSTAT    -0.54849"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "      np.array([boston['feature_names'], np.round(linear_regression.coef_,5)]).T\n",
    "    , columns = ['Feature','Coefficient']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit Learn focuses on Machine Learning.  It is less concerned with summary model statistics and more about maximizing predictive power on a hold out set.  For a more traditional statistics view, you could use the `statsmodels` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   70.88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 21 Feb 2018</td> <th>  Prob (F-statistic):</th> <td>1.47e-86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:11:59</td>     <th>  Log-Likelihood:    </th> <td> -1012.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   339</td>      <th>  AIC:               </th> <td>   2053.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   325</td>      <th>  BIC:               </th> <td>   2106.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1281</td> <td>    0.046</td> <td>   -2.762</td> <td> 0.006</td> <td>   -0.219</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0378</td> <td>    0.018</td> <td>    2.094</td> <td> 0.037</td> <td>    0.002</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0586</td> <td>    0.075</td> <td>    0.784</td> <td> 0.433</td> <td>   -0.088</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    3.2401</td> <td>    1.051</td> <td>    3.081</td> <td> 0.002</td> <td>    1.172</td> <td>    5.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  -16.2223</td> <td>    4.907</td> <td>   -3.306</td> <td> 0.001</td> <td>  -25.875</td> <td>   -6.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    3.8935</td> <td>    0.512</td> <td>    7.601</td> <td> 0.000</td> <td>    2.886</td> <td>    4.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0128</td> <td>    0.017</td> <td>   -0.771</td> <td> 0.441</td> <td>   -0.045</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -1.4233</td> <td>    0.250</td> <td>   -5.699</td> <td> 0.000</td> <td>   -1.915</td> <td>   -0.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2345</td> <td>    0.084</td> <td>    2.781</td> <td> 0.006</td> <td>    0.069</td> <td>    0.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0082</td> <td>    0.005</td> <td>   -1.739</td> <td> 0.083</td> <td>   -0.017</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.9300</td> <td>    0.160</td> <td>   -5.823</td> <td> 0.000</td> <td>   -1.244</td> <td>   -0.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0119</td> <td>    0.003</td> <td>    3.512</td> <td> 0.001</td> <td>    0.005</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.5485</td> <td>    0.061</td> <td>   -9.028</td> <td> 0.000</td> <td>   -0.668</td> <td>   -0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   33.3881</td> <td>    6.267</td> <td>    5.327</td> <td> 0.000</td> <td>   21.058</td> <td>   45.718</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>112.105</td> <th>  Durbin-Watson:     </th> <td>   2.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 426.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.405</td>  <th>  Prob(JB):          </th> <td>2.05e-93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.725</td>  <th>  Cond. No.          </th> <td>1.49e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.739\n",
       "Model:                            OLS   Adj. R-squared:                  0.729\n",
       "Method:                 Least Squares   F-statistic:                     70.88\n",
       "Date:                Wed, 21 Feb 2018   Prob (F-statistic):           1.47e-86\n",
       "Time:                        20:11:59   Log-Likelihood:                -1012.4\n",
       "No. Observations:                 339   AIC:                             2053.\n",
       "Df Residuals:                     325   BIC:                             2106.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.1281      0.046     -2.762      0.006      -0.219      -0.037\n",
       "x2             0.0378      0.018      2.094      0.037       0.002       0.073\n",
       "x3             0.0586      0.075      0.784      0.433      -0.088       0.206\n",
       "x4             3.2401      1.051      3.081      0.002       1.172       5.309\n",
       "x5           -16.2223      4.907     -3.306      0.001     -25.875      -6.570\n",
       "x6             3.8935      0.512      7.601      0.000       2.886       4.901\n",
       "x7            -0.0128      0.017     -0.771      0.441      -0.045       0.020\n",
       "x8            -1.4233      0.250     -5.699      0.000      -1.915      -0.932\n",
       "x9             0.2345      0.084      2.781      0.006       0.069       0.400\n",
       "x10           -0.0082      0.005     -1.739      0.083      -0.017       0.001\n",
       "x11           -0.9300      0.160     -5.823      0.000      -1.244      -0.616\n",
       "x12            0.0119      0.003      3.512      0.001       0.005       0.019\n",
       "x13           -0.5485      0.061     -9.028      0.000      -0.668      -0.429\n",
       "const         33.3881      6.267      5.327      0.000      21.058      45.718\n",
       "==============================================================================\n",
       "Omnibus:                      112.105   Durbin-Watson:                   2.080\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              426.846\n",
       "Skew:                           1.405   Prob(JB):                     2.05e-93\n",
       "Kurtosis:                       7.725   Cond. No.                     1.49e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "X_train_with_intercept = np.append(X_train,np.array([1]*X_train.shape[0]).reshape(-1,1),axis=1)\n",
    "\n",
    "OLS(y_train, X_train_with_intercept).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Almost every estimator in `sklearn` has  `fit()`, `predict()`, and `score()` methods. This makes swapping techniques easy.\n",
    "\n",
    "ESTIMATOR.fit(predictors, response)\n",
    "ESTIMATOR.predict(predictors, response)\n",
    "ESTIMATOR.score(predictors, response)\n",
    "\n",
    "Let's fit an OLS, ridge, lasso, elasticnet, random forest, gradient boost and decision tree using the same estimator syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Initial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.893198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.812672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.740223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.725852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.720131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.668769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.664381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model R2 Initial\n",
       "5  GradientBoostingRegressor   0.893198\n",
       "4      RandomForestRegressor   0.812672\n",
       "6      DecisionTreeRegressor   0.740223\n",
       "0           LinearRegression   0.725852\n",
       "1                      Ridge   0.720131\n",
       "3                 ElasticNet   0.668769\n",
       "2                      Lasso   0.664381"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.ensemble as ens\n",
    "import sklearn.tree as tree\n",
    "\n",
    "model_list = [\n",
    "      lm.LinearRegression() \n",
    "    , lm.Ridge(max_iter = 100000)\n",
    "    , lm.Lasso(max_iter = 100000)\n",
    "    , lm.ElasticNet(max_iter = 100000)\n",
    "    , ens.RandomForestRegressor(random_state=42)\n",
    "    , ens.GradientBoostingRegressor(random_state=42)\n",
    "    , tree.DecisionTreeRegressor(random_state=42)\n",
    "]\n",
    "\n",
    "model_names = [type(model).__name__ for model in model_list]\n",
    "\n",
    "fitted_models = [model.fit(X_train, y_train) for model in model_list]\n",
    "\n",
    "model_r2 = [model.score(X_test,y_test) for model in fitted_models]\n",
    "\n",
    "results = pd.DataFrame([model_names, model_r2], index=['Model','R2 Initial']).T\n",
    "\n",
    "results.sort_values(['R2 Initial'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The linear models do not fare as well as the ensemble techniques.  This is likely due to non-linear relationships in the underlying featureset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "Scikit-learn has a variety of transformers that take raw data and generate transformations that are better suited for certain algorithms.\n",
    "\n",
    "These transformers include StandardScaler(), PCA(), Imputer(), LabelBinarizer(), PolynomialFeature(), and so much more...\n",
    "\n",
    "Transformers are estimators too and have fit() methods to set up the transformation as well as transform() method to apply it to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit(X_train)\n",
    "\n",
    "X_train_transform = poly.transform(X_train)\n",
    "X_test_transform = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By adding 2nd degree terms to our feature set we expand our featureset from 13 features to 105.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Initial</th>\n",
       "      <th>R2 Poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.893198</td>\n",
       "      <td>0.887188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.668769</td>\n",
       "      <td>0.842125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.664381</td>\n",
       "      <td>0.838244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.812672</td>\n",
       "      <td>0.825092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.740223</td>\n",
       "      <td>0.74719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.720131</td>\n",
       "      <td>0.662576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.725852</td>\n",
       "      <td>0.486611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model R2 Initial   R2 Poly\n",
       "5  GradientBoostingRegressor   0.893198  0.887188\n",
       "3                 ElasticNet   0.668769  0.842125\n",
       "2                      Lasso   0.664381  0.838244\n",
       "4      RandomForestRegressor   0.812672  0.825092\n",
       "6      DecisionTreeRegressor   0.740223   0.74719\n",
       "1                      Ridge   0.720131  0.662576\n",
       "0           LinearRegression   0.725852  0.486611"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('By adding 2nd degree terms to our feature set we expand our featureset from ' + str(len(boston['feature_names'])) + \\\n",
    "      ' features to ' + str(len(poly.get_feature_names())) + '.')\n",
    "\n",
    "fitted_models = [model.fit(X_train_transform,y_train) for model in linear_models]\n",
    "\n",
    "model_r2 = [model.score(X_test_transform,y_test) for model in fitted_models]\n",
    "\n",
    "results = results.T.append(pd.Series(model_r2, name='R2 Poly')).T\n",
    "\n",
    "results.sort_values('R2 Poly', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn is customizable\n",
    "\n",
    "You can even work your own transformers into the workflow.  Let's explore taking the natural log of our featureset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Initial</th>\n",
       "      <th>R2 Poly</th>\n",
       "      <th>R2 Log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.893198</td>\n",
       "      <td>0.887188</td>\n",
       "      <td>0.895237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.812672</td>\n",
       "      <td>0.825092</td>\n",
       "      <td>0.824317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.725852</td>\n",
       "      <td>0.486611</td>\n",
       "      <td>0.822088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.720131</td>\n",
       "      <td>0.662576</td>\n",
       "      <td>0.786281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.740223</td>\n",
       "      <td>0.74719</td>\n",
       "      <td>0.727383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.668769</td>\n",
       "      <td>0.842125</td>\n",
       "      <td>0.669214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.664381</td>\n",
       "      <td>0.838244</td>\n",
       "      <td>0.664378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model R2 Initial   R2 Poly    R2 Log\n",
       "5  GradientBoostingRegressor   0.893198  0.887188  0.895237\n",
       "4      RandomForestRegressor   0.812672  0.825092  0.824317\n",
       "0           LinearRegression   0.725852  0.486611  0.822088\n",
       "1                      Ridge   0.720131  0.662576  0.786281\n",
       "6      DecisionTreeRegressor   0.740223   0.74719  0.727383\n",
       "3                 ElasticNet   0.668769  0.842125  0.669214\n",
       "2                      Lasso   0.664381  0.838244  0.664378"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "transformer = FunctionTransformer(np.log1p)\n",
    "\n",
    "X_train_transform = np.append(X_train,transformer.transform(X_train), axis=1)\n",
    "X_test_transform = np.append(X_test,transformer.transform(X_test), axis=1)\n",
    "\n",
    "fitted_models = [model.fit(X_train_transform,y_train) for model in linear_models]\n",
    "\n",
    "model_r2 = [model.score(X_test_transform,y_test) for model in fitted_models]\n",
    "\n",
    "results = results.T.append(pd.Series(model_r2, name='R2 Log')).T\n",
    "\n",
    "results.sort_values('R2 Log', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-learn is a scalable workflow\n",
    "\n",
    "### Pipelining\n",
    "\n",
    "The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.  Pipelines are estimators too with fit(), predict() and score() methods. \n",
    "\n",
    "\n",
    "DATA --> TRANSFORM --> FIT\n",
    "\n",
    "An example of a simple pipeline chaining polynomial transform and lasso regression together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout score:0.838244117471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "lasso = lm.Lasso(max_iter=100000)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps = [('poly', poly), ('lasso', lasso)]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Holdout score:' + str(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pipelining with GridSearchCV\n",
    "\n",
    "The real power of pipelines is realized when using them with GridSearchCV - The beauty here is that both transformers and the model maintain data separability between the train and test of each fold in the cross-validation routine.  This ensures no data leakage in evaluating estimator performance, but allows us to refine the hyperparameters of all estimators in the pipeline.\n",
    "\n",
    "### Optimize our DecisionTreeRegressor\n",
    "\n",
    "DATA --> TRANSFORM --> SPLIT --> GRID_SEARCH.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtree__criterion</th>\n",
       "      <th>dtree__max_depth</th>\n",
       "      <th>dtree__min_samples_leaf</th>\n",
       "      <th>dtree__min_samples_split</th>\n",
       "      <th>poly__degree</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mse</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>mse</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dtree__criterion dtree__max_depth dtree__min_samples_leaf  \\\n",
       "131     friedman_mse               50                       3   \n",
       "35               mse               50                       3   \n",
       "179     friedman_mse              100                       3   \n",
       "155     friedman_mse               75                       3   \n",
       "83               mse              100                       3   \n",
       "\n",
       "    dtree__min_samples_split poly__degree mean_test_score  \n",
       "131                       20            2        0.755944  \n",
       "35                        20            2        0.755944  \n",
       "179                       20            2        0.755944  \n",
       "155                       20            2        0.755944  \n",
       "83                        20            2        0.755944  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dtree = tree.DecisionTreeRegressor(random_state = random_state)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "          ('poly', poly)\n",
    "        , ('dtree', dtree)\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = dict(\n",
    "      dtree__criterion = ['mse','friedman_mse']\n",
    "    , dtree__max_depth = [25, 50, 75, 100]\n",
    "    , dtree__min_samples_leaf = [2, 3, 5, 10]\n",
    "    , dtree__min_samples_split = [5,10,20]\n",
    "    , poly__degree = [1,2])\n",
    "\n",
    "optimized_pipeline = GridSearchCV(pipe, param_grid, cv=5, refit=True)\n",
    "optimized_pipeline.fit(X_train, y_train)\n",
    "\n",
    "parameters = pd.DataFrame(optimized_pipeline.cv_results_['params'])\n",
    "\n",
    "cv_test_scores = pd.Series(optimized_pipeline.cv_results_['mean_test_score'],name='mean_test_score')\n",
    "\n",
    "parameters.T.append(cv_test_scores).T.sort_values('mean_test_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the decision tree performance on our true holdout set with the optimal hyper-parameters from the GridSearch space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameter set produces a holdout score of 0.8198.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dtree__criterion</th>\n",
       "      <td>mse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtree__max_depth</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtree__min_samples_leaf</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtree__min_samples_split</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly__degree</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Value\n",
       "dtree__criterion           mse\n",
       "dtree__max_depth            25\n",
       "dtree__min_samples_leaf      3\n",
       "dtree__min_samples_split    20\n",
       "poly__degree                 2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_score = round(optimized_pipeline.score(X_test,y_test),4)\n",
    "\n",
    "print('Optimal parameter set produces a holdout score of ' + str(holdout_score) + '.')\n",
    "pd.DataFrame(optimized_pipeline.best_params_,index=['Value']).T"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
