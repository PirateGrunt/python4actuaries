{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-Learn is a Python-based machine learning framework consisting of most classification, regression, and clustering algorithms with a variety of support capabilities creating a comprehensive ML framework.\n",
    "\n",
    "*** Need to add much more fluff about what it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-Learn is a comprehensive Machine Learning toolkit\n",
    "\n",
    "Scikit-Learn has dozens of estimators (clustering, classification, regression) \n",
    "\n",
    "*** Need to figure out a beautiful way to show how comprehensive the algorithm set is in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scikit-Learn provides utilities to manage key ML issues.\n",
    "\n",
    "** Showing train/test split because it is a requisite part of training a model to data, do more beautifully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import sklearn.datasets as datasets\n",
    "boston = datasets.load_boston()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston['data'], boston['target'], test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scikit-Learn makes fitting models simple\n",
    "\n",
    "Simple Linear Regression example\n",
    "\n",
    "Showing the basics of fitting a model using OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R_Square on holdout: 0.725851581823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.1280603983022774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.03779556927578036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.058610779677919375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>3.240070073436742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-16.222267596613126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.8935224412488014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.0127879943522895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.423268640106174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.2345130817919454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.008202611267234872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.9299505351901167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.011915140990558015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.548489997252009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature            Coefficient\n",
       "0      CRIM    -0.1280603983022774\n",
       "1        ZN    0.03779556927578036\n",
       "2     INDUS   0.058610779677919375\n",
       "3      CHAS      3.240070073436742\n",
       "4       NOX    -16.222267596613126\n",
       "5        RM     3.8935224412488014\n",
       "6       AGE    -0.0127879943522895\n",
       "7       DIS     -1.423268640106174\n",
       "8       RAD     0.2345130817919454\n",
       "9       TAX  -0.008202611267234872\n",
       "10  PTRATIO    -0.9299505351901167\n",
       "11        B   0.011915140990558015\n",
       "12    LSTAT     -0.548489997252009"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "#Fit a linear model\n",
    "linear_regression = lm.LinearRegression().fit(X_train, y_train)\n",
    "# Score the holdout set\n",
    "print('Model R_Square on holdout: ' + str(linear_regression.score(X_test,y_test)))\n",
    "# Review coefficient set\n",
    "pd.DataFrame(np.array([boston['feature_names'], linear_regression.coef_]).T,columns=['Feature','Coefficient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-Learn is standardized ML syntax\n",
    "\n",
    "Each estimator in `sklearn` has  `fit()`, `predict()`, and `score()` methods. This makes swapping techniques effortless.\n",
    "\n",
    "*** Want to show here that using fit, predict, and score accross a multitude of regressors will produce a multitude of scores with minimal code.\n",
    "\n",
    "### Swapping out various regression estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Initial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.725852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.720131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.664381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.668769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.812672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.893198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.740223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model R2 Initial\n",
       "0           LinearRegression   0.725852\n",
       "1                      Ridge   0.720131\n",
       "2                      Lasso   0.664381\n",
       "3                 ElasticNet   0.668769\n",
       "4      RandomForestRegressor   0.812672\n",
       "5  GradientBoostingRegressor   0.893198\n",
       "6      DecisionTreeRegressor   0.740223"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "import sklearn.ensemble as ens\n",
    "import sklearn.tree as tree\n",
    "max_iter = 100000\n",
    "random_state = 42\n",
    "\n",
    "# Let's pick a bunch of regression estimators\n",
    "linear_models = [lm.LinearRegression(), \n",
    "                 lm.Ridge(max_iter=max_iter),  \n",
    "                 lm.Lasso(max_iter=max_iter), \n",
    "                 lm.ElasticNet(max_iter=max_iter), \n",
    "                 ens.RandomForestRegressor(random_state=random_state), \n",
    "                 ens.GradientBoostingRegressor(random_state=random_state),\n",
    "                 tree.DecisionTreeRegressor(random_state=random_state)]\n",
    "# Capture model types\n",
    "model_names = [type(model).__name__ for model in linear_models]\n",
    "# Fit the estimators\n",
    "fitted_models = [model.fit(X_train, y_train) for model in linear_models]\n",
    "# Evaluate models on hold-out\n",
    "model_r2 = [model.score(X_test,y_test) for model in fitted_models]\n",
    "# Summarize results\n",
    "results = pd.DataFrame([model_names, model_r2], index=['Model','R2 Initial']).T\n",
    "# Print results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The linear models do not fair as well as the ensemble techniques.  This is likely due to non-linear relationships in the underlying featureset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-Learn is a feature engineering toolkit\n",
    "Scikit-learn has a variety of transformers that take raw data and generates transformations that are better suited for certain algorithms.\n",
    "These transformers include StandardScaler(), PCA(), Imputer(), LabelBinarizer(), PolynomialFeature(), and so much more...\n",
    "\n",
    "Transformers are estimators too and have fit() methods to set up the transformation as well as transform() method to apply it to new data.\n",
    "\n",
    "*** figure out a sexy way to show how comprehensive the toolkit is in feature engineering/data preprocessing capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By adding 2nd degree terms to our feature set we expand our featureset from 13 features to 105.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Initial</th>\n",
       "      <th>R2 Poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.725852</td>\n",
       "      <td>0.486611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.720131</td>\n",
       "      <td>0.662576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.664381</td>\n",
       "      <td>0.838244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.668769</td>\n",
       "      <td>0.842125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.812672</td>\n",
       "      <td>0.825092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.893198</td>\n",
       "      <td>0.887188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.740223</td>\n",
       "      <td>0.74719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model R2 Initial   R2 Poly\n",
       "0           LinearRegression   0.725852  0.486611\n",
       "1                      Ridge   0.720131  0.662576\n",
       "2                      Lasso   0.664381  0.838244\n",
       "3                 ElasticNet   0.668769  0.842125\n",
       "4      RandomForestRegressor   0.812672  0.825092\n",
       "5  GradientBoostingRegressor   0.893198  0.887188\n",
       "6      DecisionTreeRegressor   0.740223   0.74719"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Let's add second order variables to our featureset.\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit(X_train)\n",
    "\n",
    "# Transform our train and test datasets with the new polynomial features.\n",
    "X_train_transform = poly.transform(X_train)\n",
    "X_test_transform = poly.transform(X_test)\n",
    "\n",
    "print('By adding 2nd degree terms to our feature set we expand our featureset from ' + str(len(boston['feature_names'])) + \\\n",
    "      ' features to ' + str(len(poly.get_feature_names())) + '.')\n",
    "\n",
    "# Fit the estimators\n",
    "fitted_models = [model.fit(X_train_transform,y_train) for model in linear_models]\n",
    "# Evaluate models on hold-out\n",
    "model_r2 = [model.score(X_test_transform,y_test) for model in fitted_models]\n",
    "# Summarize results\n",
    "results = results.T.append(pd.Series(model_r2, name='R2 Poly')).T\n",
    "# Print results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn is customizable\n",
    "\n",
    "You can even work your own transformers into the workflow.  Let's explore taking the natural log of our featureset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Initial</th>\n",
       "      <th>R2 Poly</th>\n",
       "      <th>R2 Log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.725852</td>\n",
       "      <td>0.486611</td>\n",
       "      <td>0.822088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.720131</td>\n",
       "      <td>0.662576</td>\n",
       "      <td>0.786281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.664381</td>\n",
       "      <td>0.838244</td>\n",
       "      <td>0.664378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.668769</td>\n",
       "      <td>0.842125</td>\n",
       "      <td>0.669214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.812672</td>\n",
       "      <td>0.825092</td>\n",
       "      <td>0.824317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.893198</td>\n",
       "      <td>0.887188</td>\n",
       "      <td>0.895237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.740223</td>\n",
       "      <td>0.74719</td>\n",
       "      <td>0.727383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model R2 Initial   R2 Poly    R2 Log\n",
       "0           LinearRegression   0.725852  0.486611  0.822088\n",
       "1                      Ridge   0.720131  0.662576  0.786281\n",
       "2                      Lasso   0.664381  0.838244  0.664378\n",
       "3                 ElasticNet   0.668769  0.842125  0.669214\n",
       "4      RandomForestRegressor   0.812672  0.825092  0.824317\n",
       "5  GradientBoostingRegressor   0.893198  0.887188  0.895237\n",
       "6      DecisionTreeRegressor   0.740223   0.74719  0.727383"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log1p)\n",
    "\n",
    "# Transform our train and test datasets with the new polynomial features.\n",
    "X_train_transform = np.append(X_train,transformer.transform(X_train),axis=1)\n",
    "X_test_transform = np.append(X_test,transformer.transform(X_test),axis=1)\n",
    "\n",
    "#print('By adding log terms to our feature set we expand our featureset from ' + str(len(boston['feature_names'])) + \\\n",
    "#      ' features to ' + str(len(X_train_transform.T) + '.')\n",
    "\n",
    "# Fit the estimators\n",
    "fitted_models = [model.fit(X_train_transform,y_train) for model in linear_models]\n",
    "# Evaluate models on hold-out\n",
    "model_r2 = [model.score(X_test_transform,y_test) for model in fitted_models]\n",
    "# Summarize results\n",
    "results = results.T.append(pd.Series(model_r2, name='R2 Log')).T\n",
    "# Print results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-learn is a scalable workflow\n",
    "\n",
    "### Pipelining\n",
    "The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.  Pipelines are estimators too with fit(), predict() and score() methods. \n",
    "\n",
    "### Take a look at a simple example\n",
    "An example of a simple pipeline chaining polynomial transform and lasso regression together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An pipeline for our Lasso model produces a holdout score of :0.838244117471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Let's create our estimators\n",
    "poly = PolynomialFeatures(2)\n",
    "lasso = lm.Lasso(max_iter=100000)\n",
    "\n",
    "# Let's add them to a pipeline in the sequence we want to apply them\n",
    "pipe = Pipeline(steps=[('poly', poly), ('lasso', lasso)])\n",
    "\n",
    "# Fitting the pipeline fits each estimator in sequence\n",
    "pipe.fit(X_train, y_train)\n",
    "# Evaluate estimator on holdout\n",
    "print('An pipeline for our Lasso model produces a holdout score of :' + str(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pipelining with GridSearchCV\n",
    "The real power of pipelines is realized when using them with GridSearchCV - The beauty here is that both transformers and the model maintain data separability between the train and test of each fold in the cross-validation routine.  This ensures no data leakage in evaluating estimator performance, but allows us to refine the hyperparameters of all estimators in the pipeline.\n",
    "\n",
    "### Optimize our DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtree__criterion</th>\n",
       "      <th>dtree__max_depth</th>\n",
       "      <th>dtree__min_samples_leaf</th>\n",
       "      <th>dtree__min_samples_split</th>\n",
       "      <th>poly__degree</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mse</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>mse</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dtree__criterion dtree__max_depth dtree__min_samples_leaf  \\\n",
       "131     friedman_mse               50                       3   \n",
       "35               mse               50                       3   \n",
       "179     friedman_mse              100                       3   \n",
       "155     friedman_mse               75                       3   \n",
       "83               mse              100                       3   \n",
       "\n",
       "    dtree__min_samples_split poly__degree mean_test_score  \n",
       "131                       20            2        0.755944  \n",
       "35                        20            2        0.755944  \n",
       "179                       20            2        0.755944  \n",
       "155                       20            2        0.755944  \n",
       "83                        20            2        0.755944  "
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = tree.DecisionTreeRegressor(random_state=random_state)\n",
    "pipe = Pipeline(steps=[('poly', poly), ('dtree', dtree)])\n",
    "\n",
    "param_grid = dict(dtree__criterion =['mse','friedman_mse'],\n",
    "                  dtree__max_depth = [25, 50, 75, 100],\n",
    "             dtree__min_samples_leaf =[2, 3, 5, 10],\n",
    "             dtree__min_samples_split = [5,10,20],\n",
    "             poly__degree=[1,2])\n",
    "\n",
    "estimator = GridSearchCV(pipe, param_grid, return_train_score=True, cv=5)\n",
    "estimator.fit(X_train, y_train)\n",
    "parameters = pd.DataFrame(estimator.cv_results_['params'])\n",
    "cv_test_scores = pd.Series(estimator.cv_results_['mean_test_score'],name='mean_test_score')\n",
    "parameters.T.append(cv_test_scores).T.sort_values('mean_test_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain the decision tree on our training set with the optimal hyper-parameters from the GridSearch space and verify holdout score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An optimized pipeline for our Decision Tree Regressor produces a holdout score of 0.819812808935\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "dtree = tree.DecisionTreeRegressor(criterion='friedman_mse',max_depth=50, min_samples_leaf=3, min_samples_split=20, random_state = random_state)\n",
    "\n",
    "pipe = Pipeline(steps=[('poly', poly), ('dtree', dtree)])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print('An optimized pipeline for our Decision Tree Regressor produces a holdout score of ' + str(pipe.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
